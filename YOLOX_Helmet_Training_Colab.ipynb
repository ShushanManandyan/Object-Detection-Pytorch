{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShushanManandyan/Object-Detection-Pytorch/blob/main/YOLOX_Helmet_Training_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# YOLOX Helmet Detection Training\n",
        "\n",
        "This notebook trains YOLOX-L model on a construction safety helmet dataset.\n",
        "\n",
        "**Dataset Classes (6):**\n",
        "- construction-safety\n",
        "- helmet\n",
        "- no-helmet\n",
        "- no-vest\n",
        "- person\n",
        "- vest\n",
        "\n",
        "**Prerequisites:**\n",
        "1. Upload your dataset to Google Drive\n",
        "2. Enable GPU runtime: Runtime → Change runtime type → GPU (T4 or better)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "check_gpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc3a887-af83-4090-9c27-efc758cf7a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 17 12:17:35 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mount_drive",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087f5b7f-72c2-4bdb-9fa9-8df4da51ed68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "clone_yolox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b68279-65d0-4d2c-a6d9-8a8672a9f443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOX'...\n",
            "remote: Enumerating objects: 1940, done.\u001b[K\n",
            "remote: Total 1940 (delta 0), reused 0 (delta 0), pack-reused 1940 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1940/1940), 7.55 MiB | 14.78 MiB/s, done.\n",
            "Resolving deltas: 100% (1163/1163), done.\n",
            "/content/YOLOX\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Clone YOLOX repository\n",
        "!git clone https://github.com/Megvii-BaseDetection/YOLOX.git\n",
        "%cd YOLOX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "install_yolox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6289ca-db7d-4d2f-c03a-6bde3bf15044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 24.1.2 from /usr/local/lib/python3.12/dist-packages/pip (python 3.12)\n",
            "Obtaining file:///content/YOLOX\n",
            "  Running command python setup.py egg_info\n",
            "  /usr/local/lib/python3.12/dist-packages/setuptools/__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Requirements should be satisfied by a PEP 517 installer.\n",
            "          If you are using pip, you can try `pip install --use-pep517`.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    dist.fetch_build_eggs(dist.setup_requires)\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-ufnbkh5m/yolox.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-ufnbkh5m/yolox.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-ufnbkh5m/yolox.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-ufnbkh5m/yolox.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-ufnbkh5m/yolox.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-ufnbkh5m/yolox.egg-info/SOURCES.txt'\n",
            "  W0117 12:19:34.604000 2189 torch/utils/cpp_extension.py:630] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-ufnbkh5m/yolox.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no files found matching '*.cu' under directory 'yolox'\n",
            "  warning: no files found matching '*.cuh' under directory 'yolox'\n",
            "  warning: no files found matching '*.cc' under directory 'yolox'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-ufnbkh5m/yolox.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from yolox==0.3.0) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.12/dist-packages (from yolox==0.3.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.12/dist-packages (from yolox==0.3.0) (4.12.0.88)\n",
            "Collecting loguru (from yolox==0.3.0)\n",
            "  Obtaining dependency information for loguru from https://files.pythonhosted.org/packages/0c/29/0348de65b8cc732daa3e33e67806420b2ae89bdce2b04af740289c5c6c8c/loguru-0.7.3-py3-none-any.whl.metadata\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from yolox==0.3.0) (4.67.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from yolox==0.3.0) (0.24.0+cu126)\n",
            "Collecting thop (from yolox==0.3.0)\n",
            "  Obtaining dependency information for thop from https://files.pythonhosted.org/packages/bb/0f/72beeab4ff5221dc47127c80f8834b4bcd0cb36f6ba91c0b1d04a1233403/thop-0.1.1.post2209072238-py3-none-any.whl.metadata\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting ninja (from yolox==0.3.0)\n",
            "  Obtaining dependency information for ninja from https://files.pythonhosted.org/packages/ed/de/0e6edf44d6a04dabd0318a519125ed0415ce437ad5a1ec9b9be03d9048cf/ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from yolox==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from yolox==0.3.0) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from yolox==0.3.0) (2.19.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from yolox==0.3.0) (2.0.11)\n",
            "Collecting onnx>=1.13.0 (from yolox==0.3.0)\n",
            "  Obtaining dependency information for onnx>=1.13.0 from https://files.pythonhosted.org/packages/fb/71/d3fec0dcf9a7a99e7368112d9c765154e81da70fcba1e3121131a45c245b/onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting onnx-simplifier==0.4.10 (from yolox==0.3.0)\n",
            "  Downloading onnx-simplifier-0.4.10.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Running command python setup.py egg_info\n",
            "  /tmp/pip-install-osctp6lv/onnx-simplifier_42c7b2f36d924ee8af615ddb16d53a19/setup.py:26: DeprecationWarning: Use shutil.which instead of find_executable\n",
            "    CMAKE = find_executable('cmake')\n",
            "  fatal: not a git repository (or any of the parent directories): .git\n",
            "  fatal: not a git repository (or any of the parent directories): .git\n",
            "  /usr/local/lib/python3.12/dist-packages/setuptools/__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "  !!\n",
            "\n",
            "          ********************************************************************************\n",
            "          Requirements should be satisfied by a PEP 517 installer.\n",
            "          If you are using pip, you can try `pip install --use-pep517`.\n",
            "          ********************************************************************************\n",
            "\n",
            "  !!\n",
            "    dist.fetch_build_eggs(dist.setup_requires)\n",
            "  Traceback (most recent call last):\n",
            "    File \"<string>\", line 2, in <module>\n",
            "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "    File \"/tmp/pip-install-osctp6lv/onnx-simplifier_42c7b2f36d924ee8af615ddb16d53a19/setup.py\", line 271, in <module>\n",
            "      setuptools.setup(\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py\", line 117, in setup\n",
            "      return distutils.core.setup(**attrs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/core.py\", line 145, in setup\n",
            "      _setup_distribution = dist = klass(attrs)\n",
            "                                   ^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/setuptools/dist.py\", line 333, in __init__\n",
            "      self.metadata.version = self._normalize_version(self.metadata.version)\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/setuptools/dist.py\", line 369, in _normalize_version\n",
            "      normalized = str(Version(version))\n",
            "                       ^^^^^^^^^^^^^^^^\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/packaging/version.py\", line 202, in __init__\n",
            "      raise InvalidVersion(f\"Invalid version: {version!r}\")\n",
            "  packaging.version.InvalidVersion: Invalid version: 'unknown'\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  \u001b[1;35mfull command\u001b[0m: \u001b[34m/usr/bin/python3 -c '\u001b[0m\n",
            "\u001b[34m  exec(compile('\"'\"''\"'\"''\"'\"'\u001b[0m\n",
            "\u001b[34m  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
            "\u001b[34m  #\u001b[0m\n",
            "\u001b[34m  # - It imports setuptools before invoking setup.py, to enable projects that directly\u001b[0m\n",
            "\u001b[34m  #   import from `distutils.core` to work with newer packaging standards.\u001b[0m\n",
            "\u001b[34m  # - It provides a clear error message when setuptools is not installed.\u001b[0m\n",
            "\u001b[34m  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\u001b[0m\n",
            "\u001b[34m  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\u001b[0m\n",
            "\u001b[34m  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\u001b[0m\n",
            "\u001b[34m  # - It generates a shim setup.py, for handling setup.cfg-only projects.\u001b[0m\n",
            "\u001b[34m  import os, sys, tokenize\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  try:\u001b[0m\n",
            "\u001b[34m      import setuptools\u001b[0m\n",
            "\u001b[34m  except ImportError as error:\u001b[0m\n",
            "\u001b[34m      print(\u001b[0m\n",
            "\u001b[34m          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\u001b[0m\n",
            "\u001b[34m          \"the build environment.\",\u001b[0m\n",
            "\u001b[34m          file=sys.stderr,\u001b[0m\n",
            "\u001b[34m      )\u001b[0m\n",
            "\u001b[34m      sys.exit(1)\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  __file__ = %r\u001b[0m\n",
            "\u001b[34m  sys.argv[0] = __file__\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  if os.path.exists(__file__):\u001b[0m\n",
            "\u001b[34m      filename = __file__\u001b[0m\n",
            "\u001b[34m      with tokenize.open(__file__) as f:\u001b[0m\n",
            "\u001b[34m          setup_py_code = f.read()\u001b[0m\n",
            "\u001b[34m  else:\u001b[0m\n",
            "\u001b[34m      filename = \"<auto-generated setuptools caller>\"\u001b[0m\n",
            "\u001b[34m      setup_py_code = \"from setuptools import setup; setup()\"\u001b[0m\n",
            "\u001b[34m  \u001b[0m\n",
            "\u001b[34m  exec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
            "\u001b[34m  '\"'\"''\"'\"''\"'\"' % ('\"'\"'/tmp/pip-install-osctp6lv/onnx-simplifier_42c7b2f36d924ee8af615ddb16d53a19/setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' egg_info --egg-base /tmp/pip-pip-egg-info-6k6fhrhv\u001b[0m\n",
            "  \u001b[1;35mcwd\u001b[0m: /tmp/pip-install-osctp6lv/onnx-simplifier_42c7b2f36d924ee8af615ddb16d53a19/\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (3.0.12)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-9kf0lnw8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-9kf0lnw8\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0) (75.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0) (3.0.12)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.17.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp312-cp312-linux_x86_64.whl size=426682 sha256=29ce6a3778558f5224ff6a7a00ef2ee8cff14e6dffd7f1dfa89ddca52e2c0db6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dax3okq0/wheels/95/e6/c7/8ceda667bca7218619fea052622a0b11a37fb51c28c993fae3\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.11\n",
            "    Uninstalling pycocotools-2.0.11:\n",
            "      Successfully uninstalled pycocotools-2.0.11\n",
            "Successfully installed pycocotools-2.0\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.12/dist-packages (from pycocotools) (75.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.12/dist-packages (from pycocotools) (3.0.12)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Install YOLOX and dependencies\n",
        "!pip install -v -e .\n",
        "!pip install cython\n",
        "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!pip install pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "copy_dataset",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b41104d-5995-4b4b-81a8-fb1fab363e0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 124\n",
            "drwx------ 5 root root  4096 Jan 17 12:21 .\n",
            "drwxr-xr-x 3 root root  4096 Jan 17 12:20 ..\n",
            "-rw------- 1 root root   678 Jan 17 12:20 README.dataset.txt\n",
            "-rw------- 1 root root   910 Jan 17 12:20 README.roboflow.txt\n",
            "drwx------ 2 root root 12288 Jan 17 12:22 test\n",
            "drwx------ 2 root root 86016 Jan 17 12:21 train\n",
            "drwx------ 2 root root 12288 Jan 17 12:21 valid\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Copy dataset from Google Drive\n",
        "# IMPORTANT: Change the path to match your Google Drive folder\n",
        "# Your dataset structure should be:\n",
        "# helmet_dataset/\n",
        "#   ├── train/\n",
        "#   │   ├── _annotations.coco.json\n",
        "#   │   └── *.jpg\n",
        "#   ├── valid/\n",
        "#   │   ├── _annotations.coco.json\n",
        "#   │   └── *.jpg\n",
        "#   └── test/\n",
        "#       ├── _annotations.coco.json\n",
        "#       └── *.jpg\n",
        "\n",
        "!cp -r \"/content/drive/MyDrive/helmet_dataset\" /content/YOLOX/datasets/\n",
        "\n",
        "# Verify dataset\n",
        "!ls -la /content/YOLOX/datasets/helmet_dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "verify_dataset",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1741053b-88e9-471c-d601-94debd138610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "  Categories: ['construction-safety', 'helmet', 'no-helmet', 'no-vest', 'person', 'vest']\n",
            "  Number of training images: 997\n",
            "  Number of annotations: 6386\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Verify dataset annotations\n",
        "import json\n",
        "\n",
        "with open('/content/YOLOX/datasets/helmet_dataset/train/_annotations.coco.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(\"Dataset Info:\")\n",
        "print(f\"  Categories: {[c['name'] for c in data['categories']]}\")\n",
        "print(f\"  Number of training images: {len(data['images'])}\")\n",
        "print(f\"  Number of annotations: {len(data['annotations'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "create_dataset_class",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3c2015-ae7d-4ec1-b043-d78011683084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset class created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Create custom dataset class\n",
        "dataset_code = '''\n",
        "\"\"\"\n",
        "Helmet Dataset class for YOLOX training.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pycocotools.coco import COCO\n",
        "from yolox.data.datasets.datasets_wrapper import Dataset\n",
        "\n",
        "\n",
        "class HelmetDataset(Dataset):\n",
        "    \"\"\"\n",
        "    COCO format dataset for helmet detection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_dir,\n",
        "        json_file=\"_annotations.coco.json\",\n",
        "        name=\"train\",\n",
        "        img_size=(640, 640),\n",
        "        preproc=None,\n",
        "    ):\n",
        "        super().__init__(img_size)\n",
        "        self.data_dir = data_dir\n",
        "        self.json_file = json_file\n",
        "        self.name = name\n",
        "        self.img_size = img_size\n",
        "        self.preproc = preproc\n",
        "\n",
        "        self.coco = COCO(os.path.join(data_dir, name, json_file))\n",
        "        self.ids = list(self.coco.imgs.keys())\n",
        "\n",
        "        self.class_ids = sorted(self.coco.getCatIds())\n",
        "        cats = self.coco.loadCats(self.class_ids)\n",
        "        self.classes = tuple([c[\"name\"] for c in cats])\n",
        "\n",
        "        self.cat_to_class = {v: i for i, v in enumerate(self.class_ids)}\n",
        "        self.annotations = self._load_coco_annotations()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def _load_coco_annotations(self):\n",
        "        return [self.load_anno_from_ids(_id) for _id in self.ids]\n",
        "\n",
        "    def load_anno_from_ids(self, id_):\n",
        "        im_ann = self.coco.loadImgs(id_)[0]\n",
        "        width = im_ann[\"width\"]\n",
        "        height = im_ann[\"height\"]\n",
        "        file_name = im_ann[\"file_name\"]\n",
        "\n",
        "        anno_ids = self.coco.getAnnIds(imgIds=[id_], iscrowd=False)\n",
        "        annotations = self.coco.loadAnns(anno_ids)\n",
        "\n",
        "        objs = []\n",
        "        for obj in annotations:\n",
        "            x1 = obj[\"bbox\"][0]\n",
        "            y1 = obj[\"bbox\"][1]\n",
        "            x2 = x1 + obj[\"bbox\"][2]\n",
        "            y2 = y1 + obj[\"bbox\"][3]\n",
        "\n",
        "            if obj[\"area\"] > 0 and x2 > x1 and y2 > y1:\n",
        "                obj[\"clean_bbox\"] = [x1, y1, x2, y2]\n",
        "                obj[\"class_id\"] = self.cat_to_class[obj[\"category_id\"]]\n",
        "                objs.append(obj)\n",
        "\n",
        "        num_objs = len(objs)\n",
        "        res = np.zeros((num_objs, 5))\n",
        "\n",
        "        for ix, obj in enumerate(objs):\n",
        "            res[ix, 0:4] = obj[\"clean_bbox\"]\n",
        "            res[ix, 4] = obj[\"class_id\"]\n",
        "\n",
        "        img_info = (height, width)\n",
        "        resized_info = img_info\n",
        "\n",
        "        return (res, img_info, resized_info, file_name)\n",
        "\n",
        "    def load_anno(self, index):\n",
        "        return self.annotations[index][0]\n",
        "\n",
        "    def load_resized_img(self, index):\n",
        "        img = self.load_image(index)\n",
        "        r = min(self.img_size[0] / img.shape[0], self.img_size[1] / img.shape[1])\n",
        "        resized_img = cv2.resize(\n",
        "            img,\n",
        "            (int(img.shape[1] * r), int(img.shape[0] * r)),\n",
        "            interpolation=cv2.INTER_LINEAR,\n",
        "        ).astype(np.uint8)\n",
        "        return resized_img\n",
        "\n",
        "    def load_image(self, index):\n",
        "        file_name = self.annotations[index][3]\n",
        "        img_file = os.path.join(self.data_dir, self.name, file_name)\n",
        "        img = cv2.imread(img_file)\n",
        "        assert img is not None, f\"Image not found: {img_file}\"\n",
        "        return img\n",
        "\n",
        "    def pull_item(self, index):\n",
        "        res, img_info, resized_info, _ = self.annotations[index]\n",
        "        img = self.load_resized_img(index)\n",
        "        return img, res.copy(), img_info, index\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target, img_info, img_id = self.pull_item(index)\n",
        "\n",
        "        if self.preproc is not None:\n",
        "            img, target = self.preproc(img, target, self.input_dim)\n",
        "\n",
        "        return img, target, img_info, img_id\n",
        "'''\n",
        "\n",
        "with open('/content/YOLOX/yolox/data/datasets/helmet_dataset.py', 'w') as f:\n",
        "    f.write(dataset_code)\n",
        "\n",
        "print(\"Dataset class created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "create_exp_config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb9742c-199d-48bd-8de0-bb28189d50cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment config created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Create training experiment configuration\n",
        "import os\n",
        "os.makedirs('/content/YOLOX/exps/helmet', exist_ok=True)\n",
        "\n",
        "exp_code = '''\n",
        "\"\"\"\n",
        "YOLOX-L experiment configuration for helmet detection.\n",
        "6 classes: construction-safety, helmet, no-helmet, no-vest, person, vest\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, '/content/YOLOX')\n",
        "\n",
        "from yolox.exp import Exp as MyExp\n",
        "\n",
        "\n",
        "class Exp(MyExp):\n",
        "    def __init__(self):\n",
        "        super(Exp, self).__init__()\n",
        "\n",
        "        # Model configuration (YOLOX-L)\n",
        "        self.depth = 1.0\n",
        "        self.width = 1.0\n",
        "        self.num_classes = 6\n",
        "\n",
        "        # Input size\n",
        "        self.input_size = (640, 640)\n",
        "        self.test_size = (640, 640)\n",
        "\n",
        "        # Training settings\n",
        "        self.max_epoch = 50\n",
        "        self.warmup_epochs = 3\n",
        "        self.basic_lr_per_img = 0.01 / 64.0\n",
        "        self.weight_decay = 5e-4\n",
        "        self.momentum = 0.9\n",
        "\n",
        "        # Data augmentation\n",
        "        self.mosaic_prob = 1.0\n",
        "        self.mixup_prob = 1.0\n",
        "        self.hsv_prob = 1.0\n",
        "        self.flip_prob = 0.5\n",
        "        self.degrees = 10.0\n",
        "        self.translate = 0.1\n",
        "        self.mosaic_scale = (0.5, 1.5)\n",
        "        self.mixup_scale = (0.5, 1.5)\n",
        "        self.shear = 2.0\n",
        "\n",
        "        self.no_aug_epochs = 5\n",
        "\n",
        "        # Evaluation\n",
        "        self.eval_interval = 5\n",
        "        self.nmsthre = 0.65\n",
        "        self.test_conf = 0.01\n",
        "\n",
        "        # Experiment name\n",
        "        self.exp_name = \"helmet_yolox_l\"\n",
        "\n",
        "        # Dataset paths\n",
        "        self.data_dir = \"/content/YOLOX/datasets/helmet_dataset\"\n",
        "        self.train_ann = \"_annotations.coco.json\"\n",
        "        self.val_ann = \"_annotations.coco.json\"\n",
        "\n",
        "    def get_data_loader(self, batch_size, is_distributed, no_aug=False, cache_img=False):\n",
        "        from yolox.data import TrainTransform\n",
        "        from yolox.data.datasets.helmet_dataset import HelmetDataset\n",
        "        from yolox.data import (\n",
        "            YoloBatchSampler,\n",
        "            DataLoader,\n",
        "            InfiniteSampler,\n",
        "            MosaicDetection,\n",
        "            worker_init_reset_seed,\n",
        "        )\n",
        "\n",
        "        dataset = HelmetDataset(\n",
        "            data_dir=self.data_dir,\n",
        "            json_file=self.train_ann,\n",
        "            name=\"train\",\n",
        "            img_size=self.input_size,\n",
        "            preproc=TrainTransform(\n",
        "                max_labels=100,\n",
        "                flip_prob=self.flip_prob,\n",
        "                hsv_prob=self.hsv_prob\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        dataset = MosaicDetection(\n",
        "            dataset,\n",
        "            mosaic=not no_aug,\n",
        "            img_size=self.input_size,\n",
        "            preproc=TrainTransform(\n",
        "                max_labels=200,\n",
        "                flip_prob=self.flip_prob,\n",
        "                hsv_prob=self.hsv_prob\n",
        "            ),\n",
        "            degrees=self.degrees,\n",
        "            translate=self.translate,\n",
        "            mosaic_scale=self.mosaic_scale,\n",
        "            mixup_scale=self.mixup_scale,\n",
        "            shear=self.shear,\n",
        "            mosaic_prob=self.mosaic_prob,\n",
        "            mixup_prob=self.mixup_prob,\n",
        "        )\n",
        "\n",
        "        self.dataset = dataset\n",
        "\n",
        "        sampler = InfiniteSampler(len(self.dataset), seed=self.seed if self.seed else 0)\n",
        "\n",
        "        batch_sampler = YoloBatchSampler(\n",
        "            sampler=sampler,\n",
        "            batch_size=batch_size,\n",
        "            drop_last=False,\n",
        "            mosaic=not no_aug,\n",
        "        )\n",
        "\n",
        "        dataloader_kwargs = {\"num_workers\": 4, \"pin_memory\": True}\n",
        "        dataloader_kwargs[\"batch_sampler\"] = batch_sampler\n",
        "        dataloader_kwargs[\"worker_init_fn\"] = worker_init_reset_seed\n",
        "\n",
        "        train_loader = DataLoader(self.dataset, **dataloader_kwargs)\n",
        "\n",
        "        return train_loader\n",
        "\n",
        "    def get_eval_loader(self, batch_size, is_distributed, testdev=False, legacy=False):\n",
        "        from yolox.data import ValTransform\n",
        "        from yolox.data.datasets.helmet_dataset import HelmetDataset\n",
        "        from torch.utils.data import DataLoader\n",
        "\n",
        "        valdataset = HelmetDataset(\n",
        "            data_dir=self.data_dir,\n",
        "            json_file=self.val_ann,\n",
        "            name=\"valid\",\n",
        "            img_size=self.test_size,\n",
        "            preproc=ValTransform(legacy=legacy),\n",
        "        )\n",
        "\n",
        "        sampler = None\n",
        "\n",
        "        dataloader_kwargs = {\n",
        "            \"num_workers\": 4,\n",
        "            \"pin_memory\": True,\n",
        "            \"sampler\": sampler,\n",
        "            \"batch_size\": batch_size,\n",
        "        }\n",
        "        val_loader = DataLoader(valdataset, **dataloader_kwargs)\n",
        "\n",
        "        return val_loader\n",
        "\n",
        "    def get_evaluator(self, batch_size, is_distributed, testdev=False, legacy=False):\n",
        "        from yolox.evaluators import COCOEvaluator\n",
        "\n",
        "        val_loader = self.get_eval_loader(batch_size, is_distributed, testdev, legacy)\n",
        "        evaluator = COCOEvaluator(\n",
        "            dataloader=val_loader,\n",
        "            img_size=self.test_size,\n",
        "            confthre=self.test_conf,\n",
        "            nmsthre=self.nmsthre,\n",
        "            num_classes=self.num_classes,\n",
        "            testdev=testdev,\n",
        "        )\n",
        "        return evaluator\n",
        "'''\n",
        "\n",
        "with open('/content/YOLOX/exps/helmet/helmet_yolox_l.py', 'w') as f:\n",
        "    f.write(exp_code)\n",
        "\n",
        "print(\"Experiment config created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "download_weights",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84dd0646-3d23-45c3-9543-22227fea1346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-17 12:28:41--  https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_l.pth\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/386811486/4e1d8aa7-93cc-494a-8a10-706db8bbc57b?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-17T13%3A18%3A16Z&rscd=attachment%3B+filename%3Dyolox_l.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-17T12%3A17%3A39Z&ske=2026-01-17T13%3A18%3A16Z&sks=b&skv=2018-11-09&sig=fcwC%2F5jXC4Q2BAbs82AwaEvHZKZs3W9LKBDpFs%2BdOfc%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODY1NjUyMSwibmJmIjoxNzY4NjUyOTIxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.acZo5cxctbMehTDWUNd6PDEHq52ZMocDe6cFbLIjE5E&response-content-disposition=attachment%3B%20filename%3Dyolox_l.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2026-01-17 12:28:41--  https://release-assets.githubusercontent.com/github-production-release-asset/386811486/4e1d8aa7-93cc-494a-8a10-706db8bbc57b?sp=r&sv=2018-11-09&sr=b&spr=https&se=2026-01-17T13%3A18%3A16Z&rscd=attachment%3B+filename%3Dyolox_l.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2026-01-17T12%3A17%3A39Z&ske=2026-01-17T13%3A18%3A16Z&sks=b&skv=2018-11-09&sig=fcwC%2F5jXC4Q2BAbs82AwaEvHZKZs3W9LKBDpFs%2BdOfc%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2ODY1NjUyMSwibmJmIjoxNzY4NjUyOTIxLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.acZo5cxctbMehTDWUNd6PDEHq52ZMocDe6cFbLIjE5E&response-content-disposition=attachment%3B%20filename%3Dyolox_l.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 434357141 (414M) [application/octet-stream]\n",
            "Saving to: ‘/content/YOLOX/weights/yolox_l.pth’\n",
            "\n",
            "/content/YOLOX/weig 100%[===================>] 414.23M  29.8MB/s    in 12s     \n",
            "\n",
            "2026-01-17 12:28:53 (34.7 MB/s) - ‘/content/YOLOX/weights/yolox_l.pth’ saved [434357141/434357141]\n",
            "\n",
            "total 415M\n",
            "-rw-r--r-- 1 root root 415M Dec  8  2021 yolox_l.pth\n"
          ]
        }
      ],
      "source": [
        "# Step 9: Download YOLOX-L pre-trained weights\n",
        "!mkdir -p /content/YOLOX/weights\n",
        "!wget -O /content/YOLOX/weights/yolox_l.pth https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.1rc0/yolox_l.pth\n",
        "\n",
        "# Verify download\n",
        "!ls -lh /content/YOLOX/weights/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_model"
      },
      "outputs": [],
      "source": [
        "# Step 10: Start Training\n",
        "# Adjust batch_size based on GPU memory:\n",
        "# - T4 (16GB): batch_size=8\n",
        "# - V100 (16GB): batch_size=16\n",
        "# - A100 (40GB): batch_size=32\n",
        "\n",
        "!python /content/YOLOX/tools/train.py \\\n",
        "    -f /content/YOLOX/exps/helmet/helmet_yolox_l.py \\\n",
        "    -c /content/YOLOX/weights/yolox_l.pth \\\n",
        "    -d 1 \\\n",
        "    -b 8 \\\n",
        "    --fp16 \\\n",
        "    -o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tensorboard"
      },
      "outputs": [],
      "source": [
        "# Step 11 (Optional): Monitor training with TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/YOLOX/YOLOX_outputs/helmet_yolox_l/tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_model"
      },
      "outputs": [],
      "source": [
        "# Step 12: Evaluate trained model on validation set\n",
        "!python /content/YOLOX/tools/eval.py \\\n",
        "    -f /content/YOLOX/exps/helmet/helmet_yolox_l.py \\\n",
        "    -c /content/YOLOX/YOLOX_outputs/helmet_yolox_l/best_ckpt.pth \\\n",
        "    -d 1 \\\n",
        "    -b 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_demo"
      },
      "outputs": [],
      "source": [
        "# Step 13: Run inference on test images\n",
        "!python /content/YOLOX/tools/demo.py image \\\n",
        "    -f /content/YOLOX/exps/helmet/helmet_yolox_l.py \\\n",
        "    -c /content/YOLOX/YOLOX_outputs/helmet_yolox_l/best_ckpt.pth \\\n",
        "    --path /content/YOLOX/datasets/helmet_dataset/test/ \\\n",
        "    --conf 0.3 \\\n",
        "    --nms 0.65 \\\n",
        "    --save_result \\\n",
        "    --device gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display_results"
      },
      "outputs": [],
      "source": [
        "# Step 14: Display inference results\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "result_images = glob.glob('/content/YOLOX/YOLOX_outputs/helmet_yolox_l/vis_res/**/*.jpg', recursive=True)\n",
        "print(f\"Found {len(result_images)} result images\")\n",
        "\n",
        "if result_images:\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, img_path in enumerate(result_images[:6]):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(f'Result {i+1}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_to_drive"
      },
      "outputs": [],
      "source": [
        "# Step 15: Save trained model to Google Drive\n",
        "!mkdir -p \"/content/drive/MyDrive/yolox_helmet_model\"\n",
        "\n",
        "# Copy best checkpoint\n",
        "!cp /content/YOLOX/YOLOX_outputs/helmet_yolox_l/best_ckpt.pth \\\n",
        "    \"/content/drive/MyDrive/yolox_helmet_model/\"\n",
        "\n",
        "# Copy latest checkpoint\n",
        "!cp /content/YOLOX/YOLOX_outputs/helmet_yolox_l/latest_ckpt.pth \\\n",
        "    \"/content/drive/MyDrive/yolox_helmet_model/\"\n",
        "\n",
        "# Copy experiment config\n",
        "!cp /content/YOLOX/exps/helmet/helmet_yolox_l.py \\\n",
        "    \"/content/drive/MyDrive/yolox_helmet_model/\"\n",
        "\n",
        "# Copy dataset class\n",
        "!cp /content/YOLOX/yolox/data/datasets/helmet_dataset.py \\\n",
        "    \"/content/drive/MyDrive/yolox_helmet_model/\"\n",
        "\n",
        "print(\"Model saved to Google Drive!\")\n",
        "!ls -lh \"/content/drive/MyDrive/yolox_helmet_model/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_model"
      },
      "outputs": [],
      "source": [
        "# Step 16: Download model directly to your computer\n",
        "from google.colab import files\n",
        "files.download('/content/YOLOX/YOLOX_outputs/helmet_yolox_l/best_ckpt.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "export_onnx"
      },
      "outputs": [],
      "source": [
        "# Step 17 (Optional): Export to ONNX format for deployment\n",
        "!python /content/YOLOX/tools/export_onnx.py \\\n",
        "    -f /content/YOLOX/exps/helmet/helmet_yolox_l.py \\\n",
        "    -c /content/YOLOX/YOLOX_outputs/helmet_yolox_l/best_ckpt.pth \\\n",
        "    --output-name helmet_yolox_l.onnx\n",
        "\n",
        "# Copy ONNX model to Google Drive\n",
        "!cp helmet_yolox_l.onnx \"/content/drive/MyDrive/yolox_helmet_model/\"\n",
        "print(\"ONNX model exported!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tips"
      },
      "source": [
        "## Training Tips\n",
        "\n",
        "1. **GPU Memory**: Reduce batch size if you get OOM errors\n",
        "   - T4 (16GB): batch_size=8\n",
        "   - V100 (16GB): batch_size=16\n",
        "   - A100 (40GB): batch_size=32\n",
        "\n",
        "2. **Training Time**:\n",
        "   - 50 epochs with ~1000 images takes ~2-4 hours on T4\n",
        "\n",
        "3. **Resume Training**: If training is interrupted, use:\n",
        "   ```\n",
        "   !python /content/YOLOX/tools/train.py \\\n",
        "       -f /content/YOLOX/exps/helmet/helmet_yolox_l.py \\\n",
        "       --resume \\\n",
        "       --ckpt /content/YOLOX/YOLOX_outputs/helmet_yolox_l/latest_ckpt.pth \\\n",
        "       -d 1 -b 8 --fp16 -o\n",
        "   ```\n",
        "\n",
        "4. **Best Practices**:\n",
        "   - Use `--fp16` for faster training with mixed precision\n",
        "   - Monitor loss in TensorBoard\n",
        "   - Save checkpoints to Google Drive periodically"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}